import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
import time
import logging

# Make sure these helper files exist and contain the necessary functions
from scraper import scrape_news
from nlp_processor import extract_tickers
from inference_engine import generate_insight, analyze_sentiment

# Set up logging to see the pipeline output in the console
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s: %(message)s')

# Page config
st.set_page_config(
    page_title="AI Stock Insight Agent",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #FFFFFF;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state to store data across reruns
if 'insights_history' not in st.session_state:
    st.session_state.insights_history = []
if 'last_update' not in st.session_state:
    st.session_state.last_update = None

def fetch_and_analyze_news(source_url, article_limit):
    """
    Main pipeline to fetch, process, and analyze news articles.
    """
    logging.info("üöÄ Starting the AI Insight Agent run...")
    with st.spinner("üîç Analyzing latest market news..."):
        try:
            # --- STAGE 1: SCRAPING ---
            articles = scrape_news(url=source_url, limit=article_limit)
            if not articles:
                st.warning("Could not fetch any articles.")
                logging.warning("Could not fetch any articles. Exiting run.")
                return

            new_insights = []
            
            # --- Process each article found ---
            for article in articles:
                logging.info(f"Processing article: \"{article['title']}\"")

                # --- STAGE 2: NLP PROCESSING (Ticker Extraction) ---
                tickers = extract_tickers(article['content'])
                if not tickers:
                    logging.warning("No actionable tickers found. Moving to next article.")
                    continue
                logging.info(f"üéØ Tickers Extracted: {tickers}")

                # --- STAGE 3: INFERENCE (Sentiment Analysis) ---
                sentiment_result = analyze_sentiment(article['content'])
                logging.info(f"Sentiment analysis complete: {sentiment_result}")

                # --- FINAL STAGE: GENERATE INSIGHT ---
                insight = generate_insight(article['title'], tickers, sentiment_result)
                logging.info("üìä Final Insight Generated.")
                
                new_insights.append({
                    'timestamp': datetime.now(),
                    'title': article['title'],
                    'url': article['link'],
                    'tickers': tickers,
                    'sentiment': sentiment_result['sentiment'], # Extract the sentiment string
                    'insight': insight,
                    'content_preview': article['content'][:200] + "..."
                })

            # Add new insights to history and keep the list size manageable
            st.session_state.insights_history.extend(new_insights)
            st.session_state.insights_history = st.session_state.insights_history[-20:]
            
            st.success(f"‚úÖ Analyzed {len(new_insights)} new articles.")
            logging.info("‚úÖ Agent run complete.")

        except Exception as e:
            st.error(f"‚ùå An error occurred: {str(e)}")
            logging.error(f"An error occurred during the pipeline: {str(e)}")

def display_insights(insights_container, sentiment_container, companies_container):
    """
    Renders the collected insights and analytics in the UI.
    """
    if not st.session_state.insights_history:
        insights_container.info("üëã Click 'Fetch Latest News' to start analyzing!")
        return
    
    # Latest insights display
    with insights_container:
        st.subheader("üí° Latest Insights")
        for data in reversed(st.session_state.insights_history[-5:]):
            sentiment_colors = {'Positive': '#28a745', 'Negative': '#dc3545', 'Neutral': '#6c757d'}
            color = sentiment_colors.get(data['sentiment'], '#6c757d')
            
            st.markdown(f"""
            <div style="border-left: 4px solid {color}; padding-left: 1rem; margin: 1rem 0; background: #f8f9fa; border-radius: 5px;">
                <h4>{data['title']}</h4>
                <p><strong>üè¢ Companies:</strong> {', '.join(data['tickers'].keys())}</p>
                <p><strong>Sentiment:</strong> <span style="color: {color}; font-weight: bold;">{data['sentiment']}</span></p>
                <p><strong>‚è∞ Time:</strong> {data['timestamp'].strftime('%H:%M:%S')}</p>
                <details>
                    <summary>üîç View Details</summary>
                    <p>{data['content_preview']}</p>
                    <a href="{data['url']}" target="_blank">üîó Read Full Article</a>
                </details>
            </div>
            """, unsafe_allow_html=True)
    
    # Analytics Column
    sentiments = [item['sentiment'] for item in st.session_state.insights_history]
    if sentiments:
        with sentiment_container:
            st.subheader("Sentiment")
            sentiment_counts = pd.Series(sentiments).value_counts()
            fig = px.pie(values=sentiment_counts.values, names=sentiment_counts.index,
                         color_discrete_map={'Positive': '#28a745', 'Negative': '#dc3545', 'Neutral': '#6c757d'})
            fig.update_layout(height=250, margin=dict(l=0, r=0, t=0, b=0))
            st.plotly_chart(fig, use_container_width=True)
        
        with companies_container:
            st.subheader("Top Companies")
            all_tickers = [ticker for item in st.session_state.insights_history for ticker in item['tickers'].keys()]
            if all_tickers:
                company_counts = pd.Series(all_tickers).value_counts().head(5)
                for company, count in company_counts.items():
                    st.markdown(f'<div class="metric-card"><strong>{company}</strong><br>Mentioned {count} times</div>', unsafe_allow_html=True)

def main():
    """
    Main function to define the Streamlit App layout and logic.
    """
    st.markdown('<h1 class="main-header">AI Stock Insight Agent</h1>', unsafe_allow_html=True)
    
    # --- Sidebar Controls ---
    with st.sidebar:
        st.header("‚öôÔ∏è Control Panel")
        news_sources = {
            "Economic Times - Markets": "https://economictimes.indiatimes.com/markets/rssfeeds/1977021501.cms",
            "Livemint - Markets": "https://www.livemint.com/rss/markets"
            ,
            "ET Markets - Stocks": "https://economictimes.indiatimes.com/markets/stocks/rssfeeds/2146842.cms",
            "Moneycontrol - Top News": "https://www.moneycontrol.com/rss/MCtopnews.xml"
        }
        selected_source_name = st.selectbox("üì∞ News Source", list(news_sources.keys()))
        selected_source_url = news_sources[selected_source_name]

        st.subheader("üéõÔ∏è Analysis Settings")
        max_articles = st.slider("Max Articles to Process", 1, 10, 3)

        if st.button("üîÑ Fetch Latest News", type="primary"):
            fetch_and_analyze_news(selected_source_url, max_articles)
        
        st.subheader("‚öôÔ∏è Auto-Refresh")
        auto_refresh = st.checkbox("Enable Auto-Refresh")
        refresh_interval = st.selectbox("Refresh Interval (seconds)", [60, 180, 300, 600], index=1)

    # --- Main Content Area ---
    col1, col2 = st.columns([3, 1])
    with col1:
        insights_container = st.container()
    with col2:
        st.header("üìä At a Glance")
        sentiment_container = st.container()
        companies_container = st.container()

    # --- Auto-Refresh Logic ---
    if auto_refresh:
        if (st.session_state.last_update is None or
            (datetime.now() - st.session_state.last_update).total_seconds() > refresh_interval):
            fetch_and_analyze_news(selected_source_url, max_articles)
            st.session_state.last_update = datetime.now()
        
        if st.session_state.last_update:
            next_update_time = st.session_state.last_update + timedelta(seconds=refresh_interval)
            remaining_seconds = max(0, (next_update_time - datetime.now()).total_seconds())
            st.sidebar.info(f"Next refresh in: {int(remaining_seconds)}s")
        
        time.sleep(1)
        st.rerun()

    # Display all collected insights
    display_insights(insights_container, sentiment_container, companies_container)

if __name__ == "__main__":
    main()